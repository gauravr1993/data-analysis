{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim import models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [\"Superheroes are an important part of the rock culture\",\"There are many famous superheroes from Marvel comics and DC comics\",\"DC Comics has many famous superheroes like Superman, Batman, Wonder Woman, Flash, Green Lantern, Aquaman\", \"Marvel has some famous names as well like Iron Man, Captain America, thor, hulk, spiderman\", \"While DC has a superheroes team called Justice League, marvel has Avengers\",\"My personal favorites are Captain America, Iron Man, Superman and Batman\"]\n",
    "tokens = [word_tokenize(doc.lower()) for doc in sent]\n",
    "#tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(tokens)\n",
    "#dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_corpus = [dictionary.doc2bow(doc) for doc in tokens]\n",
    "#my_corpus\n",
    "words = [[(dictionary[id],count)for id,count in line] for line in my_corpus]\n",
    "#words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'personal', 'favorites', 'are', 'Captain America,', 'Iron Man,', 'Superman', 'and', 'Batman']\n"
     ]
    }
   ],
   "source": [
    "sentence_stream = [doc.split(\" \") for doc in sent]\n",
    "bigram = models.Phrases(sentence_stream, min_count=1, delimiter=b' ')\n",
    "print(bigram[sentence_stream[5]])\n",
    "#print(sentence_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['an', 0.37], ['are', 0.14], ['culture', 0.37], ['important', 0.37], ['of', 0.37], ['part', 0.37], ['rock', 0.37], ['superheroes', 0.08], ['the', 0.37]]\n",
      "[['are', 0.17], ['superheroes', 0.1], ['and', 0.28], ['comics', 0.55], ['dc', 0.17], ['famous', 0.17], ['from', 0.45], ['many', 0.28], ['marvel', 0.17], ['there', 0.45]]\n",
      "[['superheroes', 0.07], ['comics', 0.2], ['dc', 0.12], ['famous', 0.12], ['many', 0.2], [',', 0.36], ['aquaman', 0.32], ['batman', 0.2], ['flash', 0.32], ['green', 0.32], ['has', 0.12], ['lantern', 0.32], ['like', 0.2], ['superman', 0.2], ['woman', 0.32], ['wonder', 0.32]]\n",
      "[['famous', 0.12], ['marvel', 0.12], [',', 0.28], ['has', 0.12], ['like', 0.19], ['america', 0.19], ['as', 0.31], ['captain', 0.19], ['hulk', 0.31], ['iron', 0.19], ['man', 0.19], ['names', 0.31], ['some', 0.31], ['spiderman', 0.31], ['thor', 0.31], ['well', 0.31]]\n",
      "[['superheroes', 0.08], ['dc', 0.14], ['marvel', 0.14], [',', 0.08], ['has', 0.27], ['a', 0.35], ['avengers', 0.35], ['called', 0.35], ['justice', 0.35], ['league', 0.35], ['team', 0.35], ['while', 0.35]]\n",
      "[['are', 0.16], ['and', 0.25], [',', 0.18], ['batman', 0.25], ['superman', 0.25], ['america', 0.25], ['captain', 0.25], ['iron', 0.25], ['man', 0.25], ['favorites', 0.41], ['my', 0.41], ['personal', 0.41]]\n"
     ]
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(my_corpus, smartirs='ntc')\n",
    "for doc in tfidf[my_corpus]:\n",
    "    print([[dictionary[id], np.around(freq, decimals=2)] for id, freq in doc])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
