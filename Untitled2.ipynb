{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = api.load(\"text8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [wd for wd in dataset]\n",
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = models.phrases.Phrases(dataset, min_count=3, threshold=10)\n",
    "#print(bigram[dataset[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [\"What do french know about French Revolution. french knew nothing about French revolution. learn about french revolution. let's study french revolution\"]\n",
    "doc = [word_tokenize(d.lower()) for d in sent]\n",
    "#doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big = Phrases(doc,min_count=1)\n",
    "big[doc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram = Phrases(big[doc],min_count=1)\n",
    "trigram[big[doc[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human computer interaction', 'and', 'machine learning', 'has', 'now', 'become', 'a', 'trending', 'research', 'area']\n",
      "[['the', 'mayor', 'of', 'new', 'york', 'was', 'there'], ['human', 'computer', 'interaction', 'and', 'machine', 'learning', 'has', 'now', 'become', 'a', 'trending', 'research', 'area'], ['human', 'computer', 'interaction', 'is', 'interesting'], ['human', 'computer', 'interaction', 'is', 'a', 'pretty', 'interesting', 'subject'], ['human', 'computer', 'interaction', 'is', 'a', 'great', 'and', 'new', 'subject'], ['machine', 'learning', 'can', 'be', 'useful', 'sometimes'], ['new', 'york', 'mayor', 'was', 'present'], ['I', 'love', 'machine', 'learning', 'because', 'it', 'is', 'a', 'new', 'subject', 'area'], ['human', 'computer', 'interaction', 'helps', 'people', 'to', 'get', 'user', 'friendly', 'applications']]\n"
     ]
    }
   ],
   "source": [
    "documents = [\"the mayor of new york was there\", \"human computer interaction and machine learning has now become a trending research area\",\"human computer interaction is interesting\",\"human computer interaction is a pretty interesting subject\", \"human computer interaction is a great and new subject\", \"machine learning can be useful sometimes\",\"new york mayor was present\", \"I love machine learning because it is a new subject area\", \"human computer interaction helps people to get user friendly applications\"]\n",
    "sentence_stream = [doc.split(\" \") for doc in documents]\n",
    "bigram = Phrases(sentence_stream, min_count=1, delimiter=b' ')\n",
    "trigram = Phrases(bigram[sentence_stream], min_count=1, delimiter=b' ')\n",
    "\n",
    "print(trigram[bigram[sentence_stream[1]]])\n",
    "print(sentence_stream)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
